{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:34:44.552630",
     "start_time": "2016-07-25T22:34:43.730132"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import dill\n",
    "from datetime import timedelta\n",
    "from csv_pkl_sql import save_it, pkl_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T05:32:58.431504",
     "start_time": "2016-07-25T05:32:54.941108"
    }
   },
   "source": [
    "## Scrape appropriate date and location for weather data\n",
    "First requires finding closest airport for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:34:46.169704",
     "start_time": "2016-07-25T22:34:46.131103"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/01_latitude_longitude_google.pkl', 'r') as fh:\n",
    "    lat_long_data = dill.load(fh)\n",
    "lat_long_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:07.834738",
     "start_time": "2016-07-25T22:35:07.710699"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>kind</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_runway</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BAHIA BLANCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BHI</td>\n",
       "      <td>SAZB</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-38.725</td>\n",
       "      <td>-62.169</td>\n",
       "      <td>8579.0</td>\n",
       "      <td>COMANDANTE ESPORA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  FAA IATA  ICAO    kind  latitude  longitude  max_runway  \\\n",
       "56  BAHIA BLANCA  NaN  BHI  SAZB  Medium   -38.725    -62.169      8579.0   \n",
       "\n",
       "                 name    country state  \n",
       "56  COMANDANTE ESPORA  Argentina   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/02_airport_information_fallingrain.pkl', 'r') as fh:\n",
    "    airport_info = dill.load(fh)\n",
    "airport_info.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation for closest airport is crude, given that it doesn't convert latitude and longitude to distance but rather uses them directly. Given the relatively short distances involved, I think this is fine for a first pass of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:27.234236",
     "start_time": "2016-07-25T22:35:27.111072"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2062, 2) (1606, 1, 2) (1606, 2062) (1606,)\n"
     ]
    }
   ],
   "source": [
    "airport_coords = airport_info[['latitude', 'longitude']].values[np.newaxis, :]\n",
    "places_coords = np.rollaxis(lat_long_data[['latitude','longitude']].values[np.newaxis, :], 0, -1)\n",
    "\n",
    "dist_coords = ((places_coords - airport_coords)**2).sum(axis=-1)\n",
    "min_coords = dist_coords.argmin(axis=1)\n",
    "\n",
    "print airport_coords.shape, places_coords.shape, dist_coords.shape, min_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:31.338911",
     "start_time": "2016-07-25T22:35:31.318641"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 3)\n",
      "(1606, 9)\n"
     ]
    }
   ],
   "source": [
    "# Transfer the coordinates to the latitude/longitude data\n",
    "merge_data = lat_long_data.copy()\n",
    "\n",
    "print merge_data.shape\n",
    "\n",
    "merge_data['airport_index'] = airport_info.index[min_coords]\n",
    "\n",
    "# Now grap the airport and location info\n",
    "df = airport_info.loc[merge_data.airport_index, ['country','name','FAA','IATA','ICAO']]\n",
    "merge_data[['country','name','FAA','IATA','ICAO']] = df.set_index(merge_data.index)\n",
    "\n",
    "print merge_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:32.938013",
     "start_time": "2016-07-25T22:35:32.899057"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>airport_index</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina-Cordoba</td>\n",
       "      <td>-31.420083</td>\n",
       "      <td>-64.188776</td>\n",
       "      <td>149</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AMBROSIO L V TARAVELLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COR</td>\n",
       "      <td>SACO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina-Entre_Rios</td>\n",
       "      <td>-31.774665</td>\n",
       "      <td>-60.495646</td>\n",
       "      <td>398</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>GENERAL URQUIZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRA</td>\n",
       "      <td>SAAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina-Santa_Fe</td>\n",
       "      <td>-31.610658</td>\n",
       "      <td>-60.697294</td>\n",
       "      <td>527</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>SAUCE VIEJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SFN</td>\n",
       "      <td>SAAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude  airport_index    country  \\\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559             80  Argentina   \n",
       "1          Argentina-CABA -34.603684 -58.381559             80  Argentina   \n",
       "2       Argentina-Cordoba -31.420083 -64.188776            149  Argentina   \n",
       "3    Argentina-Entre_Rios -31.774665 -60.495646            398  Argentina   \n",
       "4      Argentina-Santa_Fe -31.610658 -60.697294            527  Argentina   \n",
       "\n",
       "                       name  FAA IATA  ICAO  \n",
       "0  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "1  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "2    AMBROSIO L V TARAVELLA  NaN  COR  SACO  \n",
       "3           GENERAL URQUIZA  NaN  PRA  SAAP  \n",
       "4               SAUCE VIEJO  NaN  SFN  SAAV  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:36.349960",
     "start_time": "2016-07-25T22:35:36.281641"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO WRITE THIS MATRIX OUT\n",
    "pkl_it(merge_data, '../pkl/04_merged_latitude_longitude_airport_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine with infection date data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:35:44.491730",
     "start_time": "2016-07-25T22:35:42.835940"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date                location\n",
       "0  2016-03-19  Argentina-Buenos_Aires"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/03_infection_data_initial_import.pkl','r') as fh:\n",
    "    infection_data = dill.load(fh)\n",
    "infection_data = infection_data[['report_date','location']]\n",
    "infection_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:37:49.943588",
     "start_time": "2016-07-25T22:37:49.827506"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107940, 2) (1606, 9)\n",
      "(34442, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Catamarca</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTC</td>\n",
       "      <td>SANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chaco</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RES</td>\n",
       "      <td>SARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chubut</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL</td>\n",
       "      <td>SAVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_date                location    country  FAA IATA  ICAO\n",
       "0   2016-03-19  Argentina-Buenos_Aires  Argentina  NaN  AEP  SABE\n",
       "6   2016-03-19          Argentina-CABA  Argentina  NaN  AEP  SABE\n",
       "12  2016-03-19     Argentina-Catamarca  Argentina  NaN  CTC  SANC\n",
       "18  2016-03-19         Argentina-Chaco  Argentina  NaN  RES  SARE\n",
       "24  2016-03-19        Argentina-Chubut  Argentina  NaN  REL  SAVT"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print infection_data.shape, merge_data.shape\n",
    "\n",
    "merge_all = pd.merge(infection_data, \n",
    "                     merge_data[['location','country','FAA','IATA','ICAO']], \n",
    "                     on='location', \n",
    "                     how='left').drop_duplicates()\n",
    "\n",
    "print merge_all.shape\n",
    "\n",
    "merge_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scrape from weather underground. I want time shifted data, so need to get one and two weeks beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T22:46:37.960183",
     "start_time": "2016-07-25T22:46:37.910847"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_scrape = (merge_all[['report_date','country','IATA','ICAO']]\n",
    "                  .drop_duplicates()\n",
    "                  .set_index(['country','IATA','ICAO'])\n",
    "                  )\n",
    "\n",
    "weather_scrape['report_date1'] = weather_scrape.report_date - timedelta(days=7)\n",
    "weather_scrape['report_date2'] = weather_scrape.report_date - timedelta(days=14)\n",
    "\n",
    "weather_scrape = (weather_scrape\n",
    "                  .stack()\n",
    "                  .reset_index(level=-1, drop=True)\n",
    "                  .reset_index()\n",
    "                  .rename(columns={0:'report_date'})\n",
    "                  .dropna(subset=['IATA','ICAO'], how='all')\n",
    "                 )\n",
    "\n",
    "weather_scrape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T23:06:16.683183",
     "start_time": "2016-07-25T23:06:16.660301"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def scrape_weekly_weather(df_row):\n",
    "#     # Scrape the weekly data table\n",
    "#     url_fmt = 'https://www.wunderground.com/history/airport/{}/{}/{}/{}/WeeklyHistory.html'\n",
    "    \n",
    "#     try:\n",
    "#         url = url_fmt.format(df_row.ICAO, df_row.report_date.year, \n",
    "#                              df_row.report_date.month, df_row.report_date.day)\n",
    "#     except:\n",
    "#         url = url_fmt.format(df_row.IATA, df_row.report_date.year, \n",
    "#                              df_row.report_date.month, df_row.report_date.day)\n",
    "    \n",
    "#     try:\n",
    "#         table = pd.read_html(url)[0].dropna(subset=['Max','Avg','Min','Sum'], how='all')\n",
    "#         table.columns = ['Measurement','Max','Avg','Min','Sum']\n",
    "#         table.set_index('Measurement', inplace=True)\n",
    "#         table = table.stack()\n",
    "#     except:\n",
    "#         table = pd.Series({'NULL':np.NaN}, index=pd.Index([0]))\n",
    "    \n",
    "#     return table\n",
    "\n",
    "def scrape_weekly_weather(date, df_row):\n",
    "    # Scrape the weekly data table\n",
    "    url_fmt = 'https://www.wunderground.com/history/airport/{}/{}/{}/{}/WeeklyHistory.html'\n",
    "    \n",
    "    try:\n",
    "        url = url_fmt.format(df_row.ICAO, date.year, \n",
    "                             date.month, date.day)\n",
    "    except:\n",
    "        url = url_fmt.format(df_row.IATA, date.year, \n",
    "                             date.month, date.day)\n",
    "    \n",
    "    try:\n",
    "        table = pd.read_html(url)[0].dropna(subset=['Max','Avg','Min','Sum'], how='all')\n",
    "        table.columns = ['Measurement','Max','Avg','Min','Sum']\n",
    "        table.set_index('Measurement', inplace=True)\n",
    "        table = table.stack()\n",
    "        time.sleep(1.0)\n",
    "    except:\n",
    "        table = pd.Series({'NULL':np.NaN}, index=pd.Index([0]))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T23:21:59.152862",
     "start_time": "2016-07-25T23:21:59.141019"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = pd.DatetimeIndex(weather_scrape.report_date.sort_values().unique())\n",
    "airport_list = weather_scrape[['ICAO','IATA']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T23:23:51.658939",
     "start_time": "2016-07-25T23:23:51.651301"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 258, 34572)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list.shape[0], airport_list.shape[0], date_list.shape[0] * airport_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T23:26:06.663183",
     "start_time": "2016-07-25T23:25:45.623574"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for ndate, date in enumerate(date_list[:1]):\n",
    "    \n",
    "    print ndate\n",
    "    df_list = list()\n",
    "    \n",
    "    for num,(row,dat) in enumerate(airport_list.iloc[-10:].iterrows()):\n",
    "        \n",
    "        try:\n",
    "            df = scrape_weekly_weather(date, dat)\n",
    "        except:\n",
    "            df = pd.Series({'NULL':np.NaN}, index=pd.Index([row]))\n",
    "\n",
    "        df_list.append((date, dat.name, df))\n",
    "        \n",
    "    with open('../pkl/df_list{}.pkl'.format(ndate),'w') as fh:\n",
    "        dill.dump(df_list, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T23:27:22.166628",
     "start_time": "2016-07-25T23:27:22.159058"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_list1 = list()\n",
    "# for num,(row,dat) in enumerate(weather_scrape.iloc[-10:].iterrows()):\n",
    "#     if (num % 100) == 0:\n",
    "#         print num\n",
    "        \n",
    "#     try:\n",
    "#         df = scrape_weekly_weather(dat)\n",
    "#     except:\n",
    "#         df = pd.Series({'NULL':np.NaN}, index=pd.Index([row]))\n",
    "        \n",
    "#     df_list1.append((dat.name, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_scrape_range = weather_scrape.groupby(['country','IATA','ICAO']).agg({'report_date':[min,max]})\n",
    "(weather_scrape_range[('report_date','max')] - weather_scrape_range[('report_date','min')]).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
