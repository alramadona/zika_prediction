{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:30.761375",
     "start_time": "2016-07-26T15:16:29.532386"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import dill\n",
    "from datetime import timedelta\n",
    "from csv_pkl_sql import save_it, pkl_it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-25T05:32:58.431504",
     "start_time": "2016-07-25T05:32:54.941108"
    }
   },
   "source": [
    "## Scrape appropriate date and location for weather data\n",
    "First requires finding closest airport for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:48.310528",
     "start_time": "2016-07-26T15:16:48.285105"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/01_latitude_longitude_google.pkl', 'r') as fh:\n",
    "    lat_long_data = dill.load(fh)\n",
    "lat_long_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:49.013015",
     "start_time": "2016-07-26T15:16:48.907441"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>kind</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_runway</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BAHIA BLANCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BHI</td>\n",
       "      <td>SAZB</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-38.725</td>\n",
       "      <td>-62.169</td>\n",
       "      <td>8579.0</td>\n",
       "      <td>COMANDANTE ESPORA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  FAA IATA  ICAO    kind  latitude  longitude  max_runway  \\\n",
       "56  BAHIA BLANCA  NaN  BHI  SAZB  Medium   -38.725    -62.169      8579.0   \n",
       "\n",
       "                 name    country state  \n",
       "56  COMANDANTE ESPORA  Argentina   NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/02_airport_information_fallingrain.pkl', 'r') as fh:\n",
    "    airport_info = dill.load(fh)\n",
    "airport_info.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation for closest airport is crude, given that it doesn't convert latitude and longitude to distance but rather uses them directly. Given the relatively short distances involved, I think this is fine for a first pass of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:49.970063",
     "start_time": "2016-07-26T15:16:49.834755"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2062, 2) (1606, 1, 2) (1606, 2062) (1606,)\n"
     ]
    }
   ],
   "source": [
    "airport_coords = airport_info[['latitude', 'longitude']].values[np.newaxis, :]\n",
    "places_coords = np.rollaxis(lat_long_data[['latitude','longitude']].values[np.newaxis, :], 0, -1)\n",
    "\n",
    "dist_coords = ((places_coords - airport_coords)**2).sum(axis=-1)\n",
    "min_coords = dist_coords.argmin(axis=1)\n",
    "\n",
    "print airport_coords.shape, places_coords.shape, dist_coords.shape, min_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:50.851292",
     "start_time": "2016-07-26T15:16:50.833647"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1606, 3)\n",
      "(1606, 9)\n"
     ]
    }
   ],
   "source": [
    "# Transfer the coordinates to the latitude/longitude data\n",
    "merge_data = lat_long_data.copy()\n",
    "\n",
    "print merge_data.shape\n",
    "\n",
    "merge_data['airport_index'] = airport_info.index[min_coords]\n",
    "\n",
    "# Now grap the airport and location info\n",
    "df = airport_info.loc[merge_data.airport_index, ['country','name','FAA','IATA','ICAO']]\n",
    "merge_data[['country','name','FAA','IATA','ICAO']] = df.set_index(merge_data.index)\n",
    "\n",
    "print merge_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:16:52.325288",
     "start_time": "2016-07-26T15:16:52.282968"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>airport_index</th>\n",
       "      <th>country</th>\n",
       "      <th>name</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>-34.603684</td>\n",
       "      <td>-58.381559</td>\n",
       "      <td>80</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AEROPARQUE JORGE NEWBERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina-Cordoba</td>\n",
       "      <td>-31.420083</td>\n",
       "      <td>-64.188776</td>\n",
       "      <td>149</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>AMBROSIO L V TARAVELLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COR</td>\n",
       "      <td>SACO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina-Entre_Rios</td>\n",
       "      <td>-31.774665</td>\n",
       "      <td>-60.495646</td>\n",
       "      <td>398</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>GENERAL URQUIZA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRA</td>\n",
       "      <td>SAAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina-Santa_Fe</td>\n",
       "      <td>-31.610658</td>\n",
       "      <td>-60.697294</td>\n",
       "      <td>527</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>SAUCE VIEJO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SFN</td>\n",
       "      <td>SAAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 location   latitude  longitude  airport_index    country  \\\n",
       "0  Argentina-Buenos_Aires -34.603684 -58.381559             80  Argentina   \n",
       "1          Argentina-CABA -34.603684 -58.381559             80  Argentina   \n",
       "2       Argentina-Cordoba -31.420083 -64.188776            149  Argentina   \n",
       "3    Argentina-Entre_Rios -31.774665 -60.495646            398  Argentina   \n",
       "4      Argentina-Santa_Fe -31.610658 -60.697294            527  Argentina   \n",
       "\n",
       "                       name  FAA IATA  ICAO  \n",
       "0  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "1  AEROPARQUE JORGE NEWBERY  NaN  AEP  SABE  \n",
       "2    AMBROSIO L V TARAVELLA  NaN  COR  SACO  \n",
       "3           GENERAL URQUIZA  NaN  PRA  SAAP  \n",
       "4               SAUCE VIEJO  NaN  SFN  SAAV  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T17:03:58.223564",
     "start_time": "2016-07-26T17:03:58.151366"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO WRITE THIS MATRIX OUT\n",
    "pkl_it(merge_data, '04_merged_latitude_longitude_airport_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine with infection date data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:03.336152",
     "start_time": "2016-07-26T15:17:01.666967"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date                location\n",
       "0  2016-03-19  Argentina-Buenos_Aires"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../pkl/03_infection_data_initial_import.pkl','r') as fh:\n",
    "    infection_data = dill.load(fh)\n",
    "infection_data = infection_data[['report_date','location']]\n",
    "infection_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:03.470790",
     "start_time": "2016-07-26T15:17:03.338616"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107940, 2) (1606, 9)\n",
      "(34442, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>FAA</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Buenos_Aires</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-CABA</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AEP</td>\n",
       "      <td>SABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Catamarca</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTC</td>\n",
       "      <td>SANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chaco</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RES</td>\n",
       "      <td>SARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>Argentina-Chubut</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REL</td>\n",
       "      <td>SAVT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   report_date                location    country  FAA IATA  ICAO\n",
       "0   2016-03-19  Argentina-Buenos_Aires  Argentina  NaN  AEP  SABE\n",
       "6   2016-03-19          Argentina-CABA  Argentina  NaN  AEP  SABE\n",
       "12  2016-03-19     Argentina-Catamarca  Argentina  NaN  CTC  SANC\n",
       "18  2016-03-19         Argentina-Chaco  Argentina  NaN  RES  SARE\n",
       "24  2016-03-19        Argentina-Chubut  Argentina  NaN  REL  SAVT"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print infection_data.shape, merge_data.shape\n",
    "\n",
    "merge_all = pd.merge(infection_data, \n",
    "                     merge_data[['location','country','FAA','IATA','ICAO']], \n",
    "                     on='location', \n",
    "                     how='left').drop_duplicates()\n",
    "\n",
    "print merge_all.shape\n",
    "\n",
    "merge_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now scrape from weather underground. I want time shifted data, so need to get one and two weeks beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:07.232763",
     "start_time": "2016-07-26T15:17:07.178907"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_scrape = (merge_all[['report_date','country','IATA','ICAO']]\n",
    "                  .drop_duplicates()\n",
    "                  .set_index(['country','IATA','ICAO'])\n",
    "                  )\n",
    "\n",
    "weather_scrape['report_date1'] = weather_scrape.report_date - timedelta(days=7)\n",
    "weather_scrape['report_date2'] = weather_scrape.report_date - timedelta(days=14)\n",
    "\n",
    "weather_scrape = (weather_scrape\n",
    "                  .stack()\n",
    "                  .reset_index(level=-1, drop=True)\n",
    "                  .reset_index()\n",
    "                  .rename(columns={0:'report_date'})\n",
    "                  .dropna(subset=['IATA','ICAO'], how='all')\n",
    "                 )\n",
    "\n",
    "weather_scrape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:09.908920",
     "start_time": "2016-07-26T15:17:09.887421"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def scrape_weekly_weather(df_row):\n",
    "#     # Scrape the weekly data table\n",
    "#     url_fmt = 'https://www.wunderground.com/history/airport/{}/{}/{}/{}/WeeklyHistory.html'\n",
    "    \n",
    "#     try:\n",
    "#         url = url_fmt.format(df_row.ICAO, df_row.report_date.year, \n",
    "#                              df_row.report_date.month, df_row.report_date.day)\n",
    "#     except:\n",
    "#         url = url_fmt.format(df_row.IATA, df_row.report_date.year, \n",
    "#                              df_row.report_date.month, df_row.report_date.day)\n",
    "    \n",
    "#     try:\n",
    "#         table = pd.read_html(url)[0].dropna(subset=['Max','Avg','Min','Sum'], how='all')\n",
    "#         table.columns = ['Measurement','Max','Avg','Min','Sum']\n",
    "#         table.set_index('Measurement', inplace=True)\n",
    "#         table = table.stack()\n",
    "#     except:\n",
    "#         table = pd.Series({'NULL':np.NaN}, index=pd.Index([0]))\n",
    "    \n",
    "#     return table\n",
    "\n",
    "def scrape_weekly_weather(date, df_row):\n",
    "    # Scrape the weekly data table\n",
    "    url_fmt = 'https://www.wunderground.com/history/airport/{}/{}/{}/{}/WeeklyHistory.html'\n",
    "    \n",
    "    try:\n",
    "        url = url_fmt.format(df_row.ICAO, date.year, \n",
    "                             date.month, date.day)\n",
    "    except:\n",
    "        url = url_fmt.format(df_row.IATA, date.year, \n",
    "                             date.month, date.day)\n",
    "    \n",
    "    try:\n",
    "        table = pd.read_html(url)[0].dropna(subset=['Max','Avg','Min','Sum'], how='all')\n",
    "        table.columns = ['Measurement','Max','Avg','Min','Sum']\n",
    "        table.set_index('Measurement', inplace=True)\n",
    "        table = table.stack()\n",
    "        time.sleep(1.0)\n",
    "    except:\n",
    "        table = pd.Series({'NULL':np.NaN}, index=pd.Index([0]))\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:10.478590",
     "start_time": "2016-07-26T15:17:10.466475"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = pd.DatetimeIndex(weather_scrape.report_date.sort_values().unique())\n",
    "airport_list = weather_scrape[['ICAO','IATA']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T15:17:14.752279",
     "start_time": "2016-07-26T15:17:14.745187"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 258, 34572)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list.shape[0], airport_list.shape[0], date_list.shape[0] * airport_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-07-26T03:29:48.688Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for ndate, date in enumerate(date_list):\n",
    "    \n",
    "    print ndate\n",
    "    df_list = list()\n",
    "    \n",
    "    for num,(row,dat) in enumerate(airport_list.iterrows()):\n",
    "        \n",
    "        try:\n",
    "            df = scrape_weekly_weather(date, dat)\n",
    "        except:\n",
    "            df = pd.Series({'NULL':np.NaN}, index=pd.Index([row]))\n",
    "\n",
    "        df_list.append((date, dat.name, df))\n",
    "        \n",
    "    with open('../pkl/df_list{}.pkl'.format(ndate),'w') as fh:\n",
    "        dill.dump(df_list, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T16:50:34.207252",
     "start_time": "2016-07-26T16:43:28.272093"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_weather_data(entry):\n",
    "    index = pd.MultiIndex.from_tuples([(entry[0],\n",
    "                                        entry[1])]*len(entry[2]),\n",
    "                                      names=['date','index'])\n",
    "    \n",
    "    df = pd.DataFrame(entry[2].reset_index().values, \n",
    "                      index=index, \n",
    "                      columns=['measurement','type','value'])\n",
    "\n",
    "    mask = (df.measurement.isin(['Max Temperature','Mean Temperature',\n",
    "                                   'Min Temperature','Dew Point','Precipitation','Wind']))\n",
    "    df = df.loc[mask]\n",
    "    \n",
    "    mask = ((((df.measurement=='Precipitation')&(df.type=='Sum'))|(df.type=='Avg')) & \n",
    "            ((df.measurement=='Precipitation')&(df.type=='Avg')).pipe(np.invert))\n",
    "    df = df.loc[mask].drop(['type'], axis=1)\n",
    "    \n",
    "    df['value'] = (df.value\n",
    "                   .str.replace('-', '')\n",
    "                   .str.extract(r\"\"\"([0-9.-]+)\"\"\", expand=True)\n",
    "                   .astype(float)\n",
    "                   )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_clean = list()\n",
    "\n",
    "\n",
    "for i in range(134):\n",
    "    with open('../pkl/df_list{}.pkl'.format(i), 'r') as fh:\n",
    "        df_list = dill.load(fh)\n",
    "    \n",
    "    for df in enumerate(df_list):\n",
    "        if not df[1][2].isnull().all():\n",
    "            df_clean.append(clean_weather_data(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T16:55:29.005772",
     "start_time": "2016-07-26T16:55:09.734496"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>measurement</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015-11-14</th>\n",
       "      <th>0</th>\n",
       "      <td>Max Temperature</td>\n",
       "      <td>76.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Temperature</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Min Temperature</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dew Point</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precipitation</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       measurement  value\n",
       "date       index                         \n",
       "2015-11-14 0       Max Temperature  76.00\n",
       "           0      Mean Temperature  70.00\n",
       "           0       Min Temperature  63.00\n",
       "           0             Dew Point  58.00\n",
       "           0         Precipitation   3.31"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_combined = pd.concat(df_clean, axis=0)\n",
    "weather_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-07-26T17:01:45.809518",
     "start_time": "2016-07-26T17:01:45.722708"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_combined = pd.merge(weather_combined.reset_index(level=-1), \n",
    "                            airport_list, \n",
    "                            left_on='index', \n",
    "                            right_index=True).drop(['index'], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2016-07-26T21:05:25.276Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_it(weather_combined, '04_weekly_weather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
